# Comprehensive Analysis of Terraform Plan File JSON Structure and Go Parsing Libraries

Terraform, an infrastructure-as-code tool by HashiCorp, enables users to define cloud and on-premises resources in declarative configuration files. A critical component of Terraform's workflow is the `plan` command, which generates an execution plan detailing the actions Terraform will perform to achieve the desired infrastructure state. This report provides a comprehensive analysis of the JSON structure of Terraform plan files, methods for parsing them programmatically, Go libraries for this purpose, best practices, and practical applications.

## Overview

Terraform's plan file is a binary artifact generated by the `terraform plan` command. To make this data accessible for automation and analysis, Terraform provides a JSON representation via `terraform show -json <planfile>`. This JSON output encapsulates the proposed changes, resource dependencies, configuration details, and current state. The format is designed for machine readability, enabling integration with policy engines, CI/CD pipelines, and custom tooling.

## Terraform Plan File JSON Structure and Schema

### Background and Context

The JSON structure adheres to a versioned schema (currently `1.1` as of Terraform 1.1+) and provides a standardised way to programmatically analyse infrastructure changes. The format has evolved significantly since Terraform 0.12, which introduced the current JSON structure.

### Generating JSON Output

To convert a Terraform plan file to JSON format:

```bash
terraform plan -out=plan.tfplan
terraform show -json plan.tfplan > plan.json
```

### Key Components of the JSON Schema

The JSON structure includes the following primary sections:

1. **`format_version`**: Indicates the schema version (e.g., `"1.1"`)
2. **`terraform_version`**: The Terraform CLI version used
3. **`variables`**: Input variables and their resolved values
4. **`resource_changes`**: A list of resources slated for creation, modification, or deletion
5. **`output_changes`**: Modifications to output values
6. **`configuration`**: A snapshot of the Terraform configuration
7. **`checks`**: Status of preconditions and postconditions defined in the configuration

### Detailed Structure Example

```json
{
  "format_version": "1.1",
  "terraform_version": "1.6.0",
  "variables": {
    "instance_type": {
      "value": "t2.micro"
    }
  },
  "resource_changes": [
    {
      "address": "aws_instance.example",
      "module_address": "",
      "mode": "managed",
      "type": "aws_instance",
      "name": "example",
      "provider_name": "registry.terraform.io/hashicorp/aws",
      "change": {
        "actions": ["create"],
        "before": null,
        "after": {
          "ami": "ami-0c55b159cbfafe1f0",
          "instance_type": "t2.micro",
          "tags": {
            "Name": "example-instance"
          }
        },
        "after_unknown": {
          "id": true,
          "public_ip": true
        },
        "before_sensitive": {},
        "after_sensitive": {}
      }
    }
  ],
  "output_changes": {},
  "configuration": {
    "provider_config": {},
    "root_module": {
      "resources": [],
      "module_calls": {}
    }
  }
}
```

### Resource Change Actions

The `actions` field in resource changes can contain:
- `["no-op"]`: No changes required
- `["create"]`: Resource will be created
- `["read"]`: Resource will be read/imported
- `["update"]`: Resource will be updated in-place
- `["delete"]`: Resource will be destroyed
- `["delete", "create"]`: Resource will be replaced (destroyed then recreated)

## Programmatic Parsing of Terraform Plan Files

### Approaches to Parsing

There are two primary methods for parsing Terraform plan files:

1. **Direct JSON Parsing**: Using `terraform show -json` to convert the binary plan file into JSON, which is then parsed using standard JSON libraries
2. **Stdout Parsing**: Capturing the human-readable `terraform plan` output and converting it to structured data

### Challenges in Parsing

- **Sensitive Data Exposure**: Plan files may contain secrets. The JSON output redacts sensitive values, but care must be taken to avoid logging or storing this data
- **Schema Evolution**: HashiCorp increments the `format_version` for backward-incompatible changes, requiring parsers to handle multiple schema versions
- **Nested Structures**: Resources with complex configurations produce deeply nested JSON, complicating traversal
- **Provider-Specific Schemas**: Resources from different providers may include undocumented fields

## Go Libraries for Parsing Terraform Plan Files

### Official Libraries

#### 1. `hashicorp/terraform-json`

This is the official Go package maintained by HashiCorp for parsing Terraform plan and state JSON output. It provides strongly typed structs that align with Terraform's internal representations.

**Key Features:**
- Direct unmarshalling of `terraform show -json` output
- Access to resource changes, outputs, and configuration snapshots
- Compatibility with Terraform 0.12+
- Well-maintained and officially supported

**Installation:**
```bash
go get github.com/hashicorp/terraform-json
```

**Example Usage:**
```go
package main

import (
    "encoding/json"
    "fmt"
    "io/ioutil"
    "log"

    "github.com/hashicorp/terraform-json"
)

func main() {
    // Read the JSON plan file
    planData, err := ioutil.ReadFile("plan.json")
    if err != nil {
        log.Fatal(err)
    }

    // Parse the plan
    var plan tfjson.Plan
    err = json.Unmarshal(planData, &plan)
    if err != nil {
        log.Fatal(err)
    }

    // Analyse the plan
    fmt.Printf("Terraform version: %s\n", plan.TerraformVersion)
    fmt.Printf("Format version: %s\n", plan.FormatVersion)

    // Iterate through resource changes
    for _, change := range plan.ResourceChanges {
        fmt.Printf("Resource: %s\n", change.Address)
        fmt.Printf("  Type: %s\n", change.Type)
        fmt.Printf("  Actions: %v\n", change.Change.Actions)

        if change.Change.Actions.Create() {
            fmt.Println("  This resource will be created")
        }
        if change.Change.Actions.Delete() {
            fmt.Println("  This resource will be deleted")
        }
        if change.Change.Actions.Update() {
            fmt.Println("  This resource will be updated")
        }
    }
}
```

### Community-Driven Libraries

#### 2. `drlau/tfplanparse`

This library parses the stdout of `terraform plan` into structured Go objects, avoiding the need to handle sensitive plan files directly.

**Key Features:**
- Handles Terraform 0.12+ CLI output
- Redacts sensitive data by default
- Useful when plan files are not available

**Limitations:**
- Less reliable than JSON parsing due to dependency on stdout formatting
- May break with Terraform CLI output changes

#### 3. `lifeomic/terraform-plan-parser`

Converts textual `terraform plan` output to JSON, suitable for environments where plan files are unavailable.

**Key Features:**
- Converts human-readable output to structured data
- Useful for legacy systems or restricted environments

#### 4. `cycloidio/terraform-plan-parser`

A parser specifically designed for CI/CD integration with focus on extracting resource changes for reporting.

**Key Features:**
- Extract resource changes for reporting
- Integration with CI/CD pipelines
- Support for plan analysis and validation

### Custom Parsing Approaches

For simple use cases, you can define custom structs:

```go
type SimplePlan struct {
    FormatVersion    string `json:"format_version"`
    TerraformVersion string `json:"terraform_version"`
    ResourceChanges  []struct {
        Address string `json:"address"`
        Type    string `json:"type"`
        Change  struct {
            Actions []string               `json:"actions"`
            Before  map[string]interface{} `json:"before"`
            After   map[string]interface{} `json:"after"`
        } `json:"change"`
    } `json:"resource_changes"`
}
```

## Best Practices for Working with Terraform Plan JSON

### 1. Use Official Libraries

Prefer the official `terraform-json` library over community alternatives for reliability and long-term support.

### 2. Handle Sensitive Data Carefully

```go
func sanitisePlan(plan *tfjson.Plan) {
    for _, change := range plan.ResourceChanges {
        // Check for sensitive attributes
        if len(change.Change.BeforeSensitive) > 0 || len(change.Change.AfterSensitive) > 0 {
            log.Println("Warning: Plan contains sensitive data")
        }
    }
}
```

### 3. Validate Schema Versions

```go
func validateFormatVersion(plan *tfjson.Plan) error {
    supportedVersions := []string{"1.0", "1.1", "1.2"}
    for _, version := range supportedVersions {
        if plan.FormatVersion == version {
            return nil
        }
    }
    return fmt.Errorf("unsupported format version: %s", plan.FormatVersion)
}
```

### 4. Error Handling

Always implement robust error handling:

```go
func parsePlanFile(filename string) (*tfjson.Plan, error) {
    data, err := ioutil.ReadFile(filename)
    if err != nil {
        return nil, fmt.Errorf("failed to read plan file: %w", err)
    }

    var plan tfjson.Plan
    if err := json.Unmarshal(data, &plan); err != nil {
        return nil, fmt.Errorf("failed to parse plan JSON: %w", err)
    }

    // Validate format version
    if err := validateFormatVersion(&plan); err != nil {
        return nil, err
    }

    return &plan, nil
}
```

### 5. Resource Filtering

Create helper functions for common filtering operations:

```go
func getResourcesByAction(plan *tfjson.Plan, action string) []tfjson.ResourceChange {
    var filtered []tfjson.ResourceChange
    for _, change := range plan.ResourceChanges {
        for _, a := range change.Change.Actions {
            if a == action {
                filtered = append(filtered, *change)
                break
            }
        }
    }
    return filtered
}

func getResourcesByType(plan *tfjson.Plan, resourceType string) []tfjson.ResourceChange {
    var filtered []tfjson.ResourceChange
    for _, change := range plan.ResourceChanges {
        if change.Type == resourceType {
            filtered = append(filtered, *change)
        }
    }
    return filtered
}
```

## Practical Applications and Examples

### Example 1: Detecting Destructive Changes

```go
func DetectDestructiveChanges(plan *tfjson.Plan) ([]string, error) {
    var destructive []string

    for _, change := range plan.ResourceChanges {
        if change.Change.Actions.Delete() || change.Change.Actions.Replace() {
            destructive = append(destructive, change.Address)
        }
    }

    return destructive, nil
}

func main() {
    plan, err := parsePlanFile("plan.json")
    if err != nil {
        log.Fatal(err)
    }

    destructive, err := DetectDestructiveChanges(plan)
    if err != nil {
        log.Fatal(err)
    }

    if len(destructive) > 0 {
        fmt.Println("Warning: The following resources will be destroyed or replaced:")
        for _, resource := range destructive {
            fmt.Printf("  - %s\n", resource)
        }
    }
}
```

### Example 2: Cost Impact Analysis

```go
func AnalyseCostImpact(plan *tfjson.Plan) {
    expensiveResources := []string{
        "aws_rds_instance",
        "aws_elasticache_cluster",
        "aws_redshift_cluster",
    }

    for _, change := range plan.ResourceChanges {
        for _, expensive := range expensiveResources {
            if change.Type == expensive {
                if change.Change.Actions.Create() {
                    fmt.Printf("Cost Impact: Creating expensive resource %s\n", change.Address)
                }
                if change.Change.Actions.Delete() {
                    fmt.Printf("Cost Savings: Deleting expensive resource %s\n", change.Address)
                }
            }
        }
    }
}
```

### Example 3: Security Compliance Check

```go
func CheckSecurityCompliance(plan *tfjson.Plan) []string {
    var violations []string

    for _, change := range plan.ResourceChanges {
        if change.Type == "aws_s3_bucket" && change.Change.Actions.Create() {
            // Check if bucket has public access
            if after, ok := change.Change.After.(map[string]interface{}); ok {
                if acl, exists := after["acl"]; exists && acl == "public-read" {
                    violations = append(violations,
                        fmt.Sprintf("S3 bucket %s has public read access", change.Address))
                }
            }
        }

        if change.Type == "aws_security_group" {
            // Check for overly permissive security groups
            if after, ok := change.Change.After.(map[string]interface{}); ok {
                if ingress, exists := after["ingress"]; exists {
                    // Analyse ingress rules for 0.0.0.0/0
                    violations = append(violations,
                        fmt.Sprintf("Security group %s may have overly permissive rules", change.Address))
                }
            }
        }
    }

    return violations
}
```

### Example 4: Integration with Policy Engines (OPA)

```go
// Example OPA policy in Rego
/*
package terraform

deny[msg] {
    resource := input.resource_changes[_]
    resource.type == "aws_s3_bucket"
    not resource.change.after.acl in ["private", "log-delivery-write"]
    msg := sprintf("S3 bucket %s has invalid ACL", [resource.address])
}
*/

func ValidateWithOPA(plan *tfjson.Plan) error {
    // Convert plan to JSON for OPA
    planJSON, err := json.Marshal(plan)
    if err != nil {
        return err
    }

    // Send to OPA for evaluation
    // Implementation depends on OPA integration method
    // (HTTP API, embedded OPA, etc.)

    return nil
}
```

## Common Use Cases

### 1. CI/CD Integration

Integrate plan analysis into CI/CD pipelines to:
- Validate plans before applying
- Generate reports of planned changes
- Enforce policy compliance
- Prevent destructive changes in production

### 2. Cost Management

- Extract resource configurations for cost estimation
- Compare before/after states for cost impact analysis
- Identify expensive resources being created or modified

### 3. Security and Compliance

- Scan for security misconfigurations
- Validate resource permissions and access patterns
- Ensure compliance with organisational policies

### 4. Change Management

- Generate human-readable change summaries
- Track resource lifecycle across deployments
- Provide audit trails for infrastructure changes

## Challenges and Limitations

### 1. Version Compatibility

Parsers must account for differences between Terraform versions. Terraform 0.12 introduced significant changes to the JSON format, and subsequent versions continue to evolve the schema.

### 2. Provider-Specific Complexity

Different cloud providers expose varying resource schemas, making generic parsing challenging. Some providers may include undocumented or provider-specific fields.

### 3. Performance Considerations

Large infrastructure plans can result in multi-megabyte JSON files with thousands of resources, impacting parsing performance and memory usage.

### 4. Sensitive Data Handling

Plan files may contain sensitive information such as:
- Database passwords
- API keys
- Private keys
- Personal data

Proper handling and redaction of sensitive data is crucial.

### 5. Limited Documentation

Community libraries often lack comprehensive documentation, requiring developers to reverse-engineer functionality from source code.

## Future Directions and Recommendations

### 1. Standardisation

HashiCorp continues to work on stabilising the JSON schema to reduce breaking changes and foster ecosystem growth. The `format_version` field helps manage this evolution.

### 2. Enhanced Tooling

The ecosystem is moving towards:
- Better integration with policy-as-code tools
- Improved performance for large plans
- More sophisticated analysis capabilities

### 3. Community Growth

The Terraform community continues to develop tools that build upon the JSON plan format, including:
- Policy engines like Open Policy Agent (OPA)
- Cost analysis tools
- Security scanning solutions

## Recommended Implementation Approach

For most Go applications working with Terraform plan files, follow this approach:

1. **Use the official `terraform-json` library** for parsing
2. **Implement comprehensive error handling** for file I/O and JSON parsing
3. **Validate format versions** to ensure compatibility
4. **Create reusable helper functions** for common analysis tasks
5. **Handle sensitive data appropriately** with proper logging and storage practices
6. **Test with various Terraform versions** to ensure compatibility

## Complete Example Implementation

```go
package main

import (
    "encoding/json"
    "fmt"
    "io/ioutil"
    "log"
    "os"

    "github.com/hashicorp/terraform-json"
)

type PlanAnalyser struct {
    plan *tfjson.Plan
}

func NewPlanAnalyser(filename string) (*PlanAnalyser, error) {
    plan, err := parsePlanFile(filename)
    if err != nil {
        return nil, err
    }

    return &PlanAnalyser{plan: plan}, nil
}

func (pa *PlanAnalyser) GetSummary() map[string]int {
    summary := make(map[string]int)

    for _, change := range pa.plan.ResourceChanges {
        for _, action := range change.Change.Actions {
            summary[action]++
        }
    }

    return summary
}

func (pa *PlanAnalyser) GetResourcesByType() map[string][]string {
    byType := make(map[string][]string)

    for _, change := range pa.plan.ResourceChanges {
        byType[change.Type] = append(byType[change.Type], change.Address)
    }

    return byType
}

func (pa *PlanAnalyser) HasDestructiveChanges() bool {
    for _, change := range pa.plan.ResourceChanges {
        if change.Change.Actions.Delete() || change.Change.Actions.Replace() {
            return true
        }
    }
    return false
}

func parsePlanFile(filename string) (*tfjson.Plan, error) {
    if _, err := os.Stat(filename); os.IsNotExist(err) {
        return nil, fmt.Errorf("plan file does not exist: %s", filename)
    }

    data, err := ioutil.ReadFile(filename)
    if err != nil {
        return nil, fmt.Errorf("failed to read plan file: %w", err)
    }

    var plan tfjson.Plan
    if err := json.Unmarshal(data, &plan); err != nil {
        return nil, fmt.Errorf("failed to parse plan JSON: %w", err)
    }

    return &plan, nil
}

func main() {
    if len(os.Args) < 2 {
        log.Fatal("Usage: go run main.go <plan.json>")
    }

    analyser, err := NewPlanAnalyser(os.Args[1])
    if err != nil {
        log.Fatal(err)
    }

    // Print summary
    fmt.Printf("Terraform Plan Analysis\n")
    fmt.Printf("======================\n")
    fmt.Printf("Terraform Version: %s\n", analyser.plan.TerraformVersion)
    fmt.Printf("Format Version: %s\n", analyser.plan.FormatVersion)
    fmt.Printf("\n")

    // Action summary
    summary := analyser.GetSummary()
    fmt.Printf("Planned Actions:\n")
    for action, count := range summary {
        fmt.Printf("  %s: %d resources\n", action, count)
    }
    fmt.Printf("\n")

    // Resource types
    byType := analyser.GetResourcesByType()
    fmt.Printf("Resources by Type:\n")
    for resourceType, addresses := range byType {
        fmt.Printf("  %s: %d resources\n", resourceType, len(addresses))
    }
    fmt.Printf("\n")

    // Destructive changes warning
    if analyser.HasDestructiveChanges() {
        fmt.Printf("⚠️  WARNING: This plan contains destructive changes!\n")
    } else {
        fmt.Printf("✅ No destructive changes detected.\n")
    }
}
```

## Conclusion

The Terraform plan JSON format provides a robust foundation for automating infrastructure governance and analysis. The official `terraform-json` library from HashiCorp offers the most reliable approach for parsing these files in Go applications. While challenges such as schema evolution, sensitive data handling, and performance considerations exist, the ecosystem's maturity ensures reliable tooling for most use cases.

Organisations should prioritise using official libraries, implement comprehensive error handling, and integrate plan analysis into their CI/CD workflows to enforce security and compliance policies. As the DevOps landscape continues to evolve, Terraform's machine-readable outputs will remain central to infrastructure automation strategies, enabling sophisticated policy enforcement, cost management, and security analysis capabilities.

The combination of structured plan data and powerful Go libraries creates opportunities for building sophisticated infrastructure governance tools that can automatically validate, analyse, and report on infrastructure changes before they are applied to production environments.
